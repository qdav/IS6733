{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sklearn.preprocessing\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics as skm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5e8710867eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/pitches.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0matbats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/atbats.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mejections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ejections.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/pitches.csv' does not exist: b'data/pitches.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/pitches.csv' does not exist: b'data/pitches.csv'",
     "output_type": "error"
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "pitches = pd.read_csv(\"data/pitches.csv\")\n",
    "atbats = pd.read_csv(\"data/atbats.csv\")\n",
    "ejections = pd.read_csv(\"data/ejections.csv\")\n",
    "games = pd.read_csv(\"data/games.csv\")\n",
    "player_names = pd.read_csv(\"data/player_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# decode labels for outcomes and pitch types\n",
    "\n",
    "# outcome codes\n",
    "outcome_code = {\n",
    "    'outcome_code' : ['B', '*B', 'S', 'C', \n",
    "                      'F', 'T', 'L', 'I', \n",
    "                      'W', 'M', 'P', \n",
    "                      'Q','R', 'X', \n",
    "                      'D', 'E', 'H',\n",
    "                      'V', 'Z'],\n",
    "    'outcome_description' : ['Ball', 'Ball in Dirt', 'Swinging Strike', 'Called Strike',\n",
    "                            'Foul', 'Foul Tip', 'Foul Bunt', 'Intentional Ball',\n",
    "                            'Swinging Strike (Blocked)', 'Missed Bunt', 'Pitchout',\n",
    "                            'Swinging Pitchout', 'Foul Pitchout', 'In Play, Out(s)', \n",
    "                            'In Play, No Outs', 'In Play, Runs', 'Hit by pitch',\n",
    "                            'V', 'Z']\n",
    "}\n",
    "outcome_code = pd.DataFrame.from_dict(outcome_code)\n",
    "\n",
    "# pitch type codes\n",
    "pitch_code = {\n",
    "    'pitch_code' : ['CH', 'CU', 'EP', 'FC', \n",
    "                      'FF', 'FO', 'FS', 'FT', \n",
    "                      'IN', 'KC', 'KN', \n",
    "                      'PO','SC', 'SI', \n",
    "                      'SL', 'UN', 'FA', 'AB'],\n",
    "    'pitch_description' : ['Changeup', 'Curveball', 'Eephus', 'Cutter',\n",
    "                            'Four-seam Fastball', 'Pitchout', 'Splitter', 'Two-seam Fastball',\n",
    "                            'Intentionall ball', 'Knuckle curve', 'Knuckleball',\n",
    "                            'Pitchout', 'Screwball', 'Sinker', \n",
    "                            'Slider', 'Unknown', 'FA', 'AB']\n",
    "}\n",
    "pitch_code = pd.DataFrame.from_dict(pitch_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pitch outcomes, probabilities\n",
    "pitch_outcome = pd.DataFrame(pitches['code'].value_counts())\n",
    "pitch_outcome.columns = ['outcome_count']\n",
    "\n",
    "outcome_df = pd.merge(pitch_outcome, outcome_code, how='left',\n",
    "        left_index=True, right_on = 'outcome_code')\n",
    "outcome_df['outcome_prob']= outcome_df['outcome_count']/outcome_df['outcome_count'].sum()\n",
    "outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# bar chart of pitch outcomes\n",
    "objects = outcome_df.outcome_description\n",
    "y_pos = np.arange(len(outcome_df.outcome_description))\n",
    "performance = outcome_df.outcome_count\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Pitches')\n",
    "plt.title('MLB 2015-2018')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pitch types, probabilities\n",
    "pitch_type = pd.DataFrame(pitches['pitch_type'].value_counts())\n",
    "pitch_type.columns = ['pitch_type_count']\n",
    "\n",
    "pitch_df = pd.merge(pitch_type, pitch_code, how='left',\n",
    "        left_index=True, right_on = 'pitch_code')\n",
    "pitch_df['pitch_prob']= pitch_df['pitch_type_count']/pitch_df['pitch_type_count'].sum()\n",
    "pitch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# bar chart of pitch types\n",
    "objects = pitch_df.pitch_description\n",
    "y_pos = np.arange(len(pitch_df.pitch_description))\n",
    "performance = pitch_df.pitch_type_count\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Pitches')\n",
    "plt.title('MLB 2015-2018')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# join all the data into all_df\n",
    "all_df = pd.merge(pitches, atbats, how='left',\n",
    "        left_on = 'ab_id', right_on = 'ab_id')\n",
    "\n",
    "pitcher_df = player_names\n",
    "pitcher_df.columns = ['pitcher_id', 'pitcher_first_name', 'pitcher_last_name']\n",
    "\n",
    "all_df = pd.merge(all_df, pitcher_df, how='left',\n",
    "        left_on = 'pitcher_id', right_on = 'pitcher_id')\n",
    "\n",
    "batter_df = player_names\n",
    "batter_df.columns = ['batter_id', 'batter_first_name', 'batter_last_name']\n",
    "\n",
    "all_df = pd.merge(all_df, batter_df, how='left',\n",
    "        left_on = 'batter_id', right_on = 'batter_id')\n",
    "\n",
    "all_df = pd.merge(all_df, games, how='left',\n",
    "        left_on = 'g_id', right_on = 'g_id')\n",
    "\n",
    "all_df = pd.merge(all_df, pitch_code, how='left',\n",
    "        left_on = 'pitch_type', right_on = 'pitch_code')\n",
    "\n",
    "all_df = pd.merge(all_df, outcome_code, how='left',\n",
    "        left_on = 'code', right_on = 'outcome_code')\n",
    "\n",
    "all_df.head(25)\n",
    "\n",
    "\n",
    "#all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pick out the columns that are known before a pitch takes place\n",
    "\n",
    "pred_df = all_df[['pitch_code', 'pitch_description', 'b_score', 'b_count', 's_count',\n",
    "                 'pitch_num', 'on_1b', 'on_2b', 'on_3b', 'batter_id', 'inning', 'o',\n",
    "                 'p_score', 'p_throws', 'stand', 'top', 'batter_id', 'pitcher_id',\n",
    "                 'attendance', 'away_team', 'home_team', 'umpire_HP',\n",
    "                 'venue_name', 'weather', 'wind', 'delay']]\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pitches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# extract weather conditions\n",
    "pred_df['temp'] = pred_df['weather'].str.extract(r'(\\d+)') # temperature\n",
    "pred_df['temp'] = pd.to_numeric(pred_df['temp'])\n",
    "pred_df['weather_cond'] = pred_df['weather'].str.extract(r'([^,]*$)') # weather condition\n",
    "pred_df['wind_mph'] = pred_df['wind'].str.extract(r'(\\d+)') # wind speed\n",
    "pred_df['wind_mph'] = pd.to_numeric(pred_df['wind_mph'])\n",
    "pred_df['wind_dir'] = pred_df['wind'].str.extract(r'([^,]*$)') # wind direction\n",
    "\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# one-hot encode all the dummy variables\n",
    "\n",
    "pitch_num_dummy = pd.get_dummies(pred_df['pitch_num'], prefix='pitch_num')\n",
    "p_throws_dummy = pd.get_dummies(pred_df['p_throws'], prefix='p_throws')\n",
    "stand_dummy = pd.get_dummies(pred_df['stand'], prefix='stand')\n",
    "away_team_dummy = pd.get_dummies(pred_df['away_team'], prefix='away_team')\n",
    "home_team_dummy = pd.get_dummies(pred_df['home_team'], prefix='home_team')\n",
    "umpire_HP_dummy = pd.get_dummies(pred_df['umpire_HP'], prefix='umpire_HP')\n",
    "venue_name_dummy = pd.get_dummies(pred_df['venue_name'], prefix='venue_name')\n",
    "weather_cond_dummy = pd.get_dummies(pred_df['weather_cond'], prefix='weather_cond')\n",
    "wind_dir_dummy = pd.get_dummies(pred_df['wind_dir'], prefix='wind_dir')\n",
    "\n",
    "encoded_df = pd.concat([pred_df, pitch_num_dummy, p_throws_dummy, stand_dummy, away_team_dummy,\n",
    "           home_team_dummy, umpire_HP_dummy, venue_name_dummy, weather_cond_dummy,\n",
    "           wind_dir_dummy], axis=1)\n",
    "encoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# factorize the dependent variable pitch code\n",
    "\n",
    "factor = pd.factorize(encoded_df['pitch_code'])\n",
    "encoded_df['pitch_code_num'] = factor[0]\n",
    "pitch_code_def = factor[1]\n",
    "print(pitch_code_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# remove categorical variables\n",
    "\n",
    "encoded_df = encoded_df.drop(['pitch_code','pitch_description', 'pitch_num', 'p_throws', 'stand',\n",
    "                             'away_team', 'home_team', 'umpire_HP', 'venue_name', 'weather_cond',\n",
    "                             'wind_dir', 'batter_id', 'pitcher_id', 'wind', 'weather'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# specify subset of records to use\n",
    "encoded_df = encoded_df[ :1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = sklearn.preprocessing.scale(encoded_df.iloc[ : , :-1]) # use all but the last column\n",
    "y = encoded_df['pitch_code_num'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# logistic regression - this fails to converge after many hours\n",
    "\n",
    "# mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='saga').fit(X_train, y_train)\n",
    "\n",
    "# print('Multinomial Logistic regression Train Accuracy')\n",
    "# metrics.accuracy_score(y_train, mul_lr.predict(X_train))\n",
    "\n",
    "# print('Multinomial Logistic regression Test Accuracy')\n",
    "# metrics.accuracy_score(y_test, mul_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# random forest model\n",
    "# https://www.codementor.io/agarrahul01/multiclass-classification-using-random-forest-on-scikit-learn-library-hkk4lwawu\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "  \n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred.size\n",
    "\n",
    "# reverse factorization\n",
    "reversefactor = dict(zip(range(18),pitch_code_def))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Pitch'], colnames=['Predicted Pitch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_x_train = pd.DataFrame(X_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(classifier.feature_importances_,\n",
    "                                   index = df_x_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "train_col_df = pd.DataFrame(encoded_df.columns)\n",
    "train_col_df\n",
    "\n",
    "fi = pd.merge(feature_importances, train_col_df, how='left',\n",
    "        left_index = True, right_index = True)\n",
    "fi.iloc[:20]\n",
    "#fi.to_csv('importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(skm.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}