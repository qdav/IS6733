{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sklearn.preprocessing\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics as skm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "    \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "pitches = pd.read_csv(\"data/pitches.csv\")\n",
    "atbats = pd.read_csv(\"data/atbats.csv\")\n",
    "ejections = pd.read_csv(\"data/ejections.csv\")\n",
    "games = pd.read_csv(\"data/games.csv\")\n",
    "player_names = pd.read_csv(\"data/player_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# decode labels for outcomes and pitch types\n",
    "\n",
    "# outcome codes\n",
    "outcome_code = {\n",
    "    'outcome_code' : ['B', '*B', 'S', 'C', \n",
    "                      'F', 'T', 'L', 'I', \n",
    "                      'W', 'M', 'P', \n",
    "                      'Q','R', 'X', \n",
    "                      'D', 'E', 'H',\n",
    "                      'V', 'Z'],\n",
    "    'outcome_description' : ['Ball', 'Ball in Dirt', 'Swinging Strike', 'Called Strike',\n",
    "                            'Foul', 'Foul Tip', 'Foul Bunt', 'Intentional Ball',\n",
    "                            'Swinging Strike (Blocked)', 'Missed Bunt', 'Pitchout',\n",
    "                            'Swinging Pitchout', 'Foul Pitchout', 'In Play, Out(s)', \n",
    "                            'In Play, No Outs', 'In Play, Runs', 'Hit by pitch',\n",
    "                            'V', 'Z']\n",
    "}\n",
    "outcome_code = pd.DataFrame.from_dict(outcome_code)\n",
    "\n",
    "# pitch type codes\n",
    "pitch_code = {\n",
    "    'pitch_code' : ['CH', 'CU', 'EP', 'FC', \n",
    "                      'FF', 'FO', 'FS', 'FT', \n",
    "                      'IN', 'KC', 'KN', \n",
    "                      'PO','SC', 'SI', \n",
    "                      'SL', 'UN', 'FA', 'AB'],\n",
    "    'pitch_description' : ['Changeup', 'Curveball', 'Eephus', 'Cutter',\n",
    "                            'Four-seam Fastball', 'Pitchout', 'Splitter', 'Two-seam Fastball',\n",
    "                            'Intentionall ball', 'Knuckle curve', 'Knuckleball',\n",
    "                            'Pitchout', 'Screwball', 'Sinker', \n",
    "                            'Slider', 'Unknown', 'FA', 'AB']\n",
    "}\n",
    "pitch_code = pd.DataFrame.from_dict(pitch_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pitch outcomes, probabilities\n",
    "pitch_outcome = pd.DataFrame(pitches['code'].value_counts())\n",
    "pitch_outcome.columns = ['outcome_count']\n",
    "\n",
    "outcome_df = pd.merge(pitch_outcome, outcome_code, how='left',\n",
    "        left_index=True, right_on = 'outcome_code')\n",
    "outcome_df['outcome_prob']= outcome_df['outcome_count']/outcome_df['outcome_count'].sum()\n",
    "outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# bar chart of pitch outcomes\n",
    "objects = outcome_df.outcome_description\n",
    "y_pos = np.arange(len(outcome_df.outcome_description))\n",
    "performance = outcome_df.outcome_count\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Pitches')\n",
    "plt.title('MLB 2015-2018')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pitch types, probabilities\n",
    "pitch_type = pd.DataFrame(pitches['pitch_type'].value_counts())\n",
    "pitch_type.columns = ['pitch_type_count']\n",
    "\n",
    "pitch_df = pd.merge(pitch_type, pitch_code, how='left',\n",
    "        left_index=True, right_on = 'pitch_code')\n",
    "pitch_df['pitch_prob']= pitch_df['pitch_type_count']/pitch_df['pitch_type_count'].sum()\n",
    "pitch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# bar chart of pitch types\n",
    "objects = pitch_df.pitch_description\n",
    "y_pos = np.arange(len(pitch_df.pitch_description))\n",
    "performance = pitch_df.pitch_type_count\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Pitches')\n",
    "plt.title('MLB 2015-2018')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# join all the data into all_df\n",
    "all_df = pd.merge(pitches, atbats, how='left',\n",
    "        left_on = 'ab_id', right_on = 'ab_id')\n",
    "\n",
    "pitcher_df = player_names\n",
    "pitcher_df.columns = ['pitcher_id', 'pitcher_first_name', 'pitcher_last_name']\n",
    "\n",
    "all_df = pd.merge(all_df, pitcher_df, how='left',\n",
    "        left_on = 'pitcher_id', right_on = 'pitcher_id')\n",
    "\n",
    "batter_df = player_names\n",
    "batter_df.columns = ['batter_id', 'batter_first_name', 'batter_last_name']\n",
    "\n",
    "all_df = pd.merge(all_df, batter_df, how='left',\n",
    "        left_on = 'batter_id', right_on = 'batter_id')\n",
    "\n",
    "all_df = pd.merge(all_df, games, how='left',\n",
    "        left_on = 'g_id', right_on = 'g_id')\n",
    "\n",
    "all_df = pd.merge(all_df, pitch_code, how='left',\n",
    "        left_on = 'pitch_type', right_on = 'pitch_code')\n",
    "\n",
    "all_df = pd.merge(all_df, outcome_code, how='left',\n",
    "        left_on = 'code', right_on = 'outcome_code')\n",
    "\n",
    "all_df.head(25)\n",
    "\n",
    "\n",
    "#all_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# pick out the columns that are known before a pitch takes place\n",
    "\n",
    "pred_df = all_df[['pitch_code', 'pitch_description', 'b_score', 'b_count', 's_count',\n",
    "                 'pitch_num', 'on_1b', 'on_2b', 'on_3b', 'batter_id', 'inning', 'o',\n",
    "                 'p_score', 'p_throws', 'stand', 'top', 'batter_id', 'pitcher_id',\n",
    "                 'attendance', 'away_team', 'home_team', 'umpire_HP',\n",
    "                 'venue_name', 'weather', 'wind', 'delay']]\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pitches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# extract weather conditions\n",
    "pred_df['temp'] = pred_df['weather'].str.extract(r'(\\d+)') # temperature\n",
    "pred_df['temp'] = pd.to_numeric(pred_df['temp'])\n",
    "pred_df['weather_cond'] = pred_df['weather'].str.extract(r'([^,]*$)') # weather condition\n",
    "pred_df['wind_mph'] = pred_df['wind'].str.extract(r'(\\d+)') # wind speed\n",
    "pred_df['wind_mph'] = pd.to_numeric(pred_df['wind_mph'])\n",
    "pred_df['wind_dir'] = pred_df['wind'].str.extract(r'([^,]*$)') # wind direction\n",
    "\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# one-hot encode all the dummy variables\n",
    "\n",
    "pitch_num_dummy = pd.get_dummies(pred_df['pitch_num'], prefix='pitch_num')\n",
    "p_throws_dummy = pd.get_dummies(pred_df['p_throws'], prefix='p_throws')\n",
    "stand_dummy = pd.get_dummies(pred_df['stand'], prefix='stand')\n",
    "away_team_dummy = pd.get_dummies(pred_df['away_team'], prefix='away_team')\n",
    "home_team_dummy = pd.get_dummies(pred_df['home_team'], prefix='home_team')\n",
    "umpire_HP_dummy = pd.get_dummies(pred_df['umpire_HP'], prefix='umpire_HP')\n",
    "venue_name_dummy = pd.get_dummies(pred_df['venue_name'], prefix='venue_name')\n",
    "weather_cond_dummy = pd.get_dummies(pred_df['weather_cond'], prefix='weather_cond')\n",
    "wind_dir_dummy = pd.get_dummies(pred_df['wind_dir'], prefix='wind_dir')\n",
    "\n",
    "encoded_df = pd.concat([pred_df, pitch_num_dummy, p_throws_dummy, stand_dummy, away_team_dummy,\n",
    "           home_team_dummy, umpire_HP_dummy, venue_name_dummy, weather_cond_dummy,\n",
    "           wind_dir_dummy], axis=1)\n",
    "encoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# factorize the dependent variable pitch code\n",
    "\n",
    "factor = pd.factorize(encoded_df['pitch_code'])\n",
    "encoded_df['pitch_code_num'] = factor[0]\n",
    "pitch_code_def = factor[1]\n",
    "print(pitch_code_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# remove categorical variables\n",
    "\n",
    "encoded_df = encoded_df.drop(['pitch_code','pitch_description', 'pitch_num', 'p_throws', 'stand',\n",
    "                             'away_team', 'home_team', 'umpire_HP', 'venue_name', 'weather_cond',\n",
    "                             'wind_dir', 'batter_id', 'pitcher_id', 'wind', 'weather'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# specify subset of records to use\n",
    "# encoded_df = encoded_df[ :100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = sklearn.preprocessing.scale(encoded_df.iloc[ : , :-1]) # use all but the last column\n",
    "y = encoded_df['pitch_code_num'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# logistic regression - this fails to converge after many hours\n",
    "\n",
    "# mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='saga').fit(X_train, y_train)\n",
    "\n",
    "# print('Multinomial Logistic regression Train Accuracy')\n",
    "# metrics.accuracy_score(y_train, mul_lr.predict(X_train))\n",
    "\n",
    "# print('Multinomial Logistic regression Test Accuracy')\n",
    "# metrics.accuracy_score(y_test, mul_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random forest model\n",
    "# https://www.codementor.io/agarrahul01/multiclass-classification-using-random-forest-on-scikit-learn-library-hkk4lwawu\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "  \n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred.size\n",
    "\n",
    "# reverse factorization\n",
    "reversefactor = dict(zip(range(18),pitch_code_def))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual Pitch'], colnames=['Predicted Pitch'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_x_train = pd.DataFrame(X_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(classifier.feature_importances_,\n",
    "                                   index = df_x_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "train_col_df = pd.DataFrame(encoded_df.columns)\n",
    "train_col_df\n",
    "\n",
    "fi = pd.merge(feature_importances, train_col_df, how='left',\n",
    "        left_index = True, right_index = True)\n",
    "fi.iloc[:20]\n",
    "#fi.to_csv('importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(skm.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-layer network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "\n",
    "X = sklearn.preprocessing.scale(encoded_df.iloc[ : , :-1]) # use all but the last column\n",
    "y = encoded_df['pitch_code_num'].values\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2, random_state=0)\n",
    "model = Sequential()\n",
    "model.add(Dense(96, input_dim=261, activation='relu'))\n",
    "model.add(Dense(96, input_dim=261, activation='relu'))\n",
    "model.add(Dense(19, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
